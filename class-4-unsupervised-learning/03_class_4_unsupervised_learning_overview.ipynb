{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Class 4 Notebook – Unsupervised Learning: Overview and Applications\n",
    "\n",
    "This notebook provides an **overview of Unsupervised Learning**, exploring its key concepts, types, and real-world applications.\n",
    "\n",
    "Unlike supervised learning (Classes 2–3), where we have labeled data and predict targets, **unsupervised learning** discovers patterns in data **without labels**. This notebook introduces the main categories and use cases.\n",
    "\n",
    "**Objective**: Understand what unsupervised learning is, when to use it, and explore its main categories:\n",
    "- Clustering (grouping similar data)\n",
    "- Dimensionality Reduction (reducing features)\n",
    "- Anomaly Detection (finding outliers)\n",
    "\n",
    "**Key idea**: Unsupervised learning helps us discover hidden structures, reduce complexity, and find patterns in unlabeled data.\n",
    "\n",
    "We'll explore:\n",
    "\n",
    "1. What is unsupervised learning?\n",
    "2. Types of unsupervised learning\n",
    "3. Clustering examples\n",
    "4. Dimensionality reduction concepts\n",
    "5. Real-world applications\n",
    "\n",
    "Run the first code cell to confirm your environment works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-badge",
   "metadata": {},
   "source": [
    "## Run in the browser (no local setup)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adzuci/ai-fundamentals/blob/main/class-4-unsupervised-learning/03_class_4_unsupervised_learning_overview.ipynb)\n",
    "\n",
    "> Tip: This notebook assumes you're comfortable with basic Python, NumPy, Pandas, and Matplotlib from Classes 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "what-is-unsupervised",
   "metadata": {},
   "source": [
    "## What is Unsupervised Learning?\n",
    "\n",
    "**Supervised Learning** (Classes 2–3):\n",
    "- We have **labeled data** (features + target)\n",
    "- Goal: Learn to predict the target from features\n",
    "- Examples: Predict house price (regression), predict pass/fail (classification)\n",
    "\n",
    "**Unsupervised Learning** (Class 4):\n",
    "- We have **unlabeled data** (only features, no target)\n",
    "- Goal: Discover hidden patterns, groups, or structures\n",
    "- Examples: Customer segmentation, anomaly detection, dimensionality reduction\n",
    "\n",
    "**Key difference**: In unsupervised learning, there's no \"right answer\" to learn from—we're exploring the data to find interesting patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1",
   "metadata": {},
   "source": [
    "## STEP 1: Install Required Libraries\n",
    "\n",
    "If running locally, install the required packages. In Colab, these are already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (run this if needed)\n",
    "# Uncomment the line below if running locally and packages aren't installed\n",
    "# !pip install numpy pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "## STEP 2: Import Libraries\n",
    "\n",
    "Import NumPy, Pandas, and Matplotlib for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment sanity check + imports\n",
    "import platform\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"OS:\", platform.system(), platform.release())\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(\"NumPy:\", np.__version__, \"| Pandas:\", pd.__version__)\n",
    "    print(\"All libraries imported successfully!\")\n",
    "except ModuleNotFoundError as exc:\n",
    "    print(\"Missing dependency:\", exc)\n",
    "    print(\"Install with: python -m pip install numpy pandas matplotlib scikit-learn\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "types",
   "metadata": {},
   "source": [
    "## Types of Unsupervised Learning\n",
    "\n",
    "Unsupervised learning can be divided into three main categories:\n",
    "\n",
    "### 1. Clustering\n",
    "- **Goal**: Group similar data points together\n",
    "- **Examples**: Customer segmentation, image compression, document grouping\n",
    "- **Algorithms**: K-Means, Hierarchical Clustering, DBSCAN\n",
    "\n",
    "### 2. Dimensionality Reduction\n",
    "- **Goal**: Reduce the number of features while preserving important information\n",
    "- **Examples**: Data visualization, noise reduction, feature selection\n",
    "- **Algorithms**: PCA (Principal Component Analysis), t-SNE, Autoencoders\n",
    "\n",
    "### 3. Anomaly Detection\n",
    "- **Goal**: Identify unusual or outlier data points\n",
    "- **Examples**: Fraud detection, network intrusion detection, quality control\n",
    "- **Algorithms**: Isolation Forest, One-Class SVM, Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clustering-example",
   "metadata": {},
   "source": [
    "## Clustering Example: Customer Segmentation\n",
    "\n",
    "Let's create a simple example to illustrate clustering. We'll generate sample customer data and visualize how clustering groups similar customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustering-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept: Create sample customer data for clustering demonstration\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate three distinct customer groups\n",
    "group1 = np.random.normal([20, 30], 5, (20, 2))  # Low income, low spending\n",
    "group2 = np.random.normal([50, 50], 5, (20, 2))  # Medium income, medium spending\n",
    "group3 = np.random.normal([80, 70], 5, (20, 2))  # High income, high spending\n",
    "\n",
    "# Combine all groups\n",
    "customers = np.vstack([group1, group2, group3])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(customers, columns=[\"Income\", \"Spending\"])\n",
    "\n",
    "print(\"Sample Customer Data:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nTotal customers: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustering-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept: Visualize customer data (before clustering)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df[\"Income\"], df[\"Spending\"], s=100, alpha=0.6, c='blue')\n",
    "plt.xlabel(\"Annual Income (thousands)\")\n",
    "plt.ylabel(\"Spending Score\")\n",
    "plt.title(\"Customer Data (Before Clustering)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Can you spot natural groups in this data?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apply-clustering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept: Apply K-Means clustering to discover customer segments\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Apply K-Means with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(df)\n",
    "\n",
    "df[\"Cluster\"] = clusters\n",
    "\n",
    "print(\"Clustering complete!\")\n",
    "print(f\"\\nCluster assignments:\")\n",
    "print(df[\"Cluster\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustered-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept: Visualize clustered customer data\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    df[\"Income\"],\n",
    "    df[\"Spending\"],\n",
    "    c=df[\"Cluster\"],\n",
    "    cmap=\"viridis\",\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "plt.scatter(\n",
    "    kmeans.cluster_centers_[:, 0],\n",
    "    kmeans.cluster_centers_[:, 1],\n",
    "    c='red',\n",
    "    marker='X',\n",
    "    s=200,\n",
    "    label='Centroids',\n",
    "    linewidths=2\n",
    ")\n",
    "plt.xlabel(\"Annual Income (thousands)\")\n",
    "plt.ylabel(\"Spending Score\")\n",
    "plt.title(\"Customer Segments (K-Means Clustering)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.show()\n",
    "\n",
    "print(\"The algorithm automatically discovered 3 customer segments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensionality-reduction",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction: Concept\n",
    "\n",
    "**Dimensionality reduction** reduces the number of features while preserving important information. This is useful for:\n",
    "- Visualizing high-dimensional data\n",
    "- Reducing noise\n",
    "- Speeding up machine learning algorithms\n",
    "- Feature selection\n",
    "\n",
    "**Principal Component Analysis (PCA)** is a common technique that finds the directions (principal components) where the data varies the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pca-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept: Demonstrate PCA for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create sample high-dimensional data (5 features)\n",
    "np.random.seed(42)\n",
    "high_dim_data = np.random.randn(100, 5)\n",
    "\n",
    "print(f\"Original data shape: {high_dim_data.shape}\")\n",
    "print(f\"Original dimensions: {high_dim_data.shape[1]}\")\n",
    "\n",
    "# Apply PCA to reduce to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(high_dim_data)\n",
    "\n",
    "print(f\"\\nReduced data shape: {reduced_data.shape}\")\n",
    "print(f\"Reduced dimensions: {reduced_data.shape[1]}\")\n",
    "print(f\"\\nVariance explained by first 2 components: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pca-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept: Visualize reduced-dimensional data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=100, alpha=0.6)\n",
    "plt.xlabel(f\"First Principal Component ({pca.explained_variance_ratio_[0]:.1%} variance)\")\n",
    "plt.ylabel(f\"Second Principal Component ({pca.explained_variance_ratio_[1]:.1%} variance)\")\n",
    "plt.title(\"Data Reduced from 5D to 2D using PCA\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"PCA reduced 5-dimensional data to 2 dimensions for visualization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applications",
   "metadata": {},
   "source": [
    "## Real-World Applications\n",
    "\n",
    "### Clustering Applications\n",
    "- **Customer Segmentation**: Group customers by purchasing behavior\n",
    "- **Image Compression**: Reduce image file size by grouping similar pixels\n",
    "- **Document Clustering**: Organize documents by topic\n",
    "- **Gene Analysis**: Group genes with similar expression patterns\n",
    "\n",
    "### Dimensionality Reduction Applications\n",
    "- **Data Visualization**: Visualize high-dimensional data in 2D/3D\n",
    "- **Feature Engineering**: Reduce noise and improve model performance\n",
    "- **Image Processing**: Compress images while preserving important features\n",
    "- **Recommendation Systems**: Reduce feature space for faster recommendations\n",
    "\n",
    "### Anomaly Detection Applications\n",
    "- **Fraud Detection**: Identify unusual credit card transactions\n",
    "- **Network Security**: Detect network intrusions\n",
    "- **Quality Control**: Find defective products in manufacturing\n",
    "- **Medical Diagnosis**: Identify unusual patient patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-learning",
   "metadata": {},
   "source": [
    "## Key Learning\n",
    "\n",
    "**Unsupervised Learning** is a powerful approach for discovering patterns in unlabeled data:\n",
    "\n",
    "- **Clustering** groups similar data points together\n",
    "- **Dimensionality Reduction** simplifies data while preserving important information\n",
    "- **Anomaly Detection** finds unusual patterns\n",
    "\n",
    "**When to use unsupervised learning**:\n",
    "- You have unlabeled data\n",
    "- You want to explore and discover patterns\n",
    "- You need to reduce data complexity\n",
    "- You want to find outliers or anomalies\n",
    "\n",
    "**Next steps**: Explore specific algorithms in detail:\n",
    "- K-Means clustering (see `01_class_4_kmeans_basics.ipynb`)\n",
    "- Hierarchical clustering (see `02_class_4_hierarchical_clustering_basics.ipynb`)\n",
    "- PCA and other dimensionality reduction techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
